{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChinaYiqun/recruitStudents/blob/main/faiss_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "NqHlm0u4AR9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c38ed16-3e27-41a9-d5bf-c4207040cd62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m728.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 115tobWH_9m_0UScfqEhH-miOrAS1_cn- --output knowledge.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxfyfhQTnIso",
        "outputId": "7f2d452c-8fed-4b60-9636-169fef8d39d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=115tobWH_9m_0UScfqEhH-miOrAS1_cn-\n",
            "To: /content/knowledge.txt\n",
            "100% 3.98k/3.98k [00:00<00:00, 12.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAG-_r9DLzZG",
        "outputId": "8817eae6-ea4f-4194-a8f2-450ec5bd4c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.915 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.915 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "张爽，女，博士，副教授, 东北大学软件学院，辽宁省本科教学名师，软件学院教学指导委员会委员，软件学院星级教师，国家级一流本科课程《软件工程》负责人。近年来，作为项目负责人负责了江苏省镔鑫钢铁集团公司智能料场项目、广西盛隆冶金有限公司项目盛隆炼钢连铸一体化计划调度模型软件系统开发、冶金原料大数据分析模型软件系统、基于大数据分析技术的电力需求决策支持平台，均取得了非常好的应用效益，其中江苏省镔鑫钢铁集团公司智能料场为国内首个智能料场。作为子课题负责人承担了国家重点研发计划项目钢铁工业网络化协同生产智能管控平台关键技术研究子课题、和东北大学基础科研课题“基于岩体破裂大数据的金属矿山安全高效开采基础”。作为主要成员，参加了国家自然科学基金重点项目“机器学习驱动的知识平面创新和网络性能优化的研究”、中国工程院高端智库项目企业内部工业互联网网络系统发展研究、和辽宁省兴辽英才计划项目面向未来互联网的数据传输与安全防护技术。研究方向：人工智能、工业软件、信息技术应用创新、大数据+、工业互联网、物联网\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import jieba\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import faiss\n",
        "simTho = 0.5\n",
        "\n",
        "def build_knowledge_rep(file):\n",
        "    # 读取文件内容\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        texts = f.readlines()\n",
        "\n",
        "    # 对每一行文本进行中文分词\n",
        "    text_tokenized = [jieba.lcut(text.strip()) for text in texts]\n",
        "\n",
        "    # 计算tf-idf\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform([' '.join(tokens) for tokens in text_tokenized])\n",
        "\n",
        "    # 使用Faiss构建向量索引\n",
        "    dim = tfidf_matrix.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(tfidf_matrix.toarray())\n",
        "\n",
        "    return index, tfidf, text_tokenized,texts\n",
        "\n",
        "\n",
        "\n",
        "def get_similarity_text(text, index, tfidf, text_tokenized,texts):\n",
        "    # 对输入文本进行中文分词\n",
        "    text_tokenized_input = jieba.lcut(text.strip())\n",
        "\n",
        "    # 计算tf-idf\n",
        "    tfidf_matrix_input = tfidf.transform([' '.join(text_tokenized_input)])\n",
        "\n",
        "    # 使用向量索引查询相似向量\n",
        "    sim, indices = index.search(tfidf_matrix_input.toarray(), k=1)\n",
        "\n",
        "    if sim > simTho:\n",
        "    # 返回相似向量所对应的文本内容\n",
        "        similar_text = texts[indices[0][0]]\n",
        "\n",
        "        return similar_text\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "\n",
        "# 示例用法\n",
        "index, tfidf, text_tokenized,texts = build_knowledge_rep('knowledge.txt')\n",
        "similar_text = get_similarity_text('张爽', index, tfidf, text_tokenized,texts)\n",
        "print(similar_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c55pcTMuOPhS"
      },
      "outputs": [],
      "source": [
        "system_content = \"你扮演一个教师,根据角色内容进行对话,你的目标是作为这个教师招收优秀的研究生,说话方式可以搞笑一些,角色内容:\"\n",
        "messages_history = [\n",
        "        {\"role\": \"system\", \"content\": \"\"},\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g4h05v1cM-M0"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "# 设置OpenAI的API秘钥\n",
        "openai.api_key = ''\n",
        "\n",
        "def get_system_prompt():\n",
        "    print(\"->:您好\")\n",
        "    first_input = input()\n",
        "    similar_text = get_similarity_text(first_input, index, tfidf, text_tokenized,texts)\n",
        "    messages_history[0][\"content\"] = system_content+similar_text\n",
        "\n",
        "    print(\"->:我是\"+similar_text.split(\"，\")[0])\n",
        "    messages_history.append({\"role\": \"user\", \"content\": first_input})\n",
        "    messages_history.append({\"role\": \"assistant\", \"content\": similar_text.split(\"，\")[0]})\n",
        "def chatgpt(input):\n",
        "    # 发送请求给ChatGPT 3.5 API\n",
        "\n",
        "    # max_tokens=100,   # 控制输出的长度\n",
        "    # temperature=0.7,  # 控制生成文本的随机性。较低的值会更加保守，较高的值会更加随机。\n",
        "    # n=1,              # 控制生成多少个候选答案\n",
        "    # stop=None,        # 控制生成文本的停止条件\n",
        "\n",
        "\n",
        "    messages_history.append({\"role\": \"user\", \"content\": input})\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages_history\n",
        "    )\n",
        "\n",
        "    # 解析API的响应并返回结果\n",
        "    output = completion.choices[0].message.content\n",
        "    messages_history.append({\"role\": \"assistant\", \"content\": output})\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_system_prompt()\n",
        "while(True):\n",
        "    q = input()\n",
        "    r = chatgpt(q)\n",
        "    print('->:'+r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWtzSWhy92yQ",
        "outputId": "977501e5-71de-43c0-e07b-4f6bf1dd3ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "->:您好\n",
            "是刘莹老师嘛？\n",
            "->:我是刘莹\n",
            "我想报考东北大学研究生\n",
            "->:哇！太好了！作为东北大学软件学院的副教授，我非常欢迎你加入我们的研究生团队！请问你对哪个专业感兴趣呢？\n",
            "软件工程\n",
            "->:软件工程是一个非常热门且有着广阔发展前景的专业，你做了一个明智的选择！作为软件学院的老师，我可以向你介绍一下我们软件工程方向的研究方向和项目。\n",
            "\n",
            "我们软件工程方向主要研究软件系统开发的理论和方法，包括软件需求工程、软件设计和架构、软件测试和维护等。同时，我们也非常关注软件工程的最新发展方向，如敏捷开发、DevOps、人工智能在软件工程中的应用等。你将有机会参与到各种精彩的项目中，不仅能够学到前沿的理论知识，还可以与企业合作，深入了解软件开发的实际应用。\n",
            "\n",
            "此外，我们软件学院还有一支优秀的师资队伍，他们在软件工程领域具有丰富的教学和研究经验。我们还与国内外的研究机构和企业保持良好的合作关系，为你提供更多宝贵的学习和实践机会。\n",
            "\n",
            "如果你有其他关于软件工程研究方向的疑问，或者任何对我们研究生招收的事宜感兴趣，请随时向我提问！\n",
            "你的研究方向是？\n",
            "->:作为一个软件学院的副教授，我的研究方向主要是智能边缘计算、服务计算、金融知识图谱等领域。在这些领域中，我致力于研究如何通过智能化的边缘计算技术来增强计算能力和提高用户体验，以及如何应用服务计算来构建高效的分布式系统。\n",
            "\n",
            "在智能边缘计算方面，我关注如何在边缘设备上进行数据处理和分析，以减少数据传输和延迟，提高效率和隐私保护。在服务计算方面，我研究如何通过服务组合和服务调度来优化分布式系统的性能和资源利用率。\n",
            "\n",
            "此外，我也对金融知识图谱进行研究，希望能够利用知识图谱的技术来构建金融领域的智能应用，例如金融风险评估和智能投资建议等。\n",
            "\n",
            "如果你对我的研究方向感兴趣，或者想了解更多关于我研究工作的细节，我非常愿意与你进一步交流！\n",
            "你太牛逼了，你发过论文嘛\n",
            "->:哈哈，谢谢夸奖！是的，我在服务计算领域的顶级杂志和会议上发表了多篇论文。近几年，在IEEE Transaction on Service Computing、IEEE ICWS、ICSOC、IEEE Cloud等国际一流期刊和会议中，我发表了多篇论文，共计30余篇。这些论文探讨了服务计算领域的关键问题，包括服务组合、服务调度、服务质量保证等，取得了一定的研究成果。\n",
            "\n",
            "当然，发表论文只是我的研究工作的一部分，我也非常注重教学和实践。我担任过数据库概论和云计算核心技术的主讲教师，并参与过多媒体教学资源的开发和教育部-IBM高校合作项目的教学工作。此外，我还获得过教育部多媒体教学资源大赛优秀奖和Google奖教金的荣誉。\n",
            "\n",
            "希望这些经历和成果能够给你留下一个对我的研究和教学水平有所了解的印象。如果你有任何进一步的问题或者关于和我合作的兴趣，随时都可以告诉我哦！\n",
            "老师，你的电话是？\n",
            "->:抱歉，由于隐私保护的原因，我不能提供个人电话号码。但是你可以通过学校的官方网站或拨打学院的办公电话来联系我。我非常乐意与你交流并解答你的问题。另外，你也可以通过电子邮件或在线平台与我沟通，我会尽快回复你的。谢谢你的理解！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages_history"
      ],
      "metadata": {
        "id": "FsO4rAEfCeHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOingI3fECxdk1pDzr44FGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}